{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import scipy.stats as sps\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "\n",
    "from copy import deepcopy\n",
    "\n",
    "from numpy import array\n",
    "from os import environ\n",
    "from os.path import join\n",
    "from sys import argv\n",
    "\n",
    "from glob import glob\n",
    "from numpy import zeros\n",
    "from os.path import basename, join\n",
    "\n",
    "from keras.models import load_model\n",
    "from os import environ\n",
    "from os.path import abspath, dirname, join\n",
    "\n",
    "from copy import copy\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras import backend as K\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.models import model_from_json\n",
    "\n",
    "from keras.layers import InputLayer, Input, Dense, Activation, Dropout, BatchNormalization, Reshape\n",
    "from keras.layers import Average, Conv2D, MaxPooling2D, Flatten\n",
    "from keras.layers.merge import Concatenate\n",
    "from keras.activations import relu, softmax, sigmoid\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Model\n",
    "\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.constraints import maxnorm\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils import np_utils\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "from keras.losses import binary_crossentropy, mse\n",
    "\n",
    "from keras.callbacks import LearningRateScheduler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class DataGenerator:\n",
    "    def __init__(self, bad_columns=None, mean=None, sd=None):\n",
    "        self.mean = mean\n",
    "        self.sd = sd\n",
    "        self.bad_columns = bad_columns\n",
    "        \n",
    "    def fit(self, X):\n",
    "        self.mean = np.mean(X ,axis=(0,1,2), keepdims=True)\n",
    "        self.sd = np.std(X ,axis=(0,1,2), keepdims=True)\n",
    "        \n",
    "    def normalize(self, X):\n",
    "        X  = (X - self.mean) / self.sd\n",
    "        X = np.clip(X, a_min=-10, a_max=10)\n",
    "        return X\n",
    "    \n",
    "    def do_fucking_job(self, X, y, feature_expander, \n",
    "                       features_win, forecast_win):\n",
    "        \n",
    "            assert min(features_win, forecast_win) > 0\n",
    "            \n",
    "            features_win -= 1\n",
    "            forecast_win -= 1\n",
    "            \n",
    "            assert max(forecast_win, features_win) < X.shape[0]\n",
    "            \n",
    "            '''\n",
    "                expander must return numpy array with shape (new_features_len)\n",
    "            '''\n",
    "            if feature_expander is not None:\n",
    "                new_features = []\n",
    "                for i in np.arange(features_win, X.shape[0]):\n",
    "                    new_features.append(feature_expander(\n",
    "                        X.iloc[i - features_win:i + 1]))\n",
    "                new_features = np.array(new_features)\n",
    "                wide = new_features.shape[1]\n",
    "                dummy_cells = np.zeros((features_win, wide))\n",
    "                new_features = np.concatenate((dummy_cells, new_features),\n",
    "                                              axis=0)\n",
    "                X = pd.concat((X, pd.DataFrame(new_features)),axis=1)\n",
    "                \n",
    "            if self.bad_columns is not None:\n",
    "                X = X.drop(self.bad_columns, axis=1)\n",
    "                \n",
    "            Y = deepcopy(X)\n",
    "            \n",
    "            for i in np.arange(forecast_win) + 1:\n",
    "                Y = pd.concat((Y, X.shift(periods=i)),axis=1)\n",
    "                \n",
    "            Y = Y.fillna(Y.median(axis=0))\n",
    "            return np.array(Y), y\n",
    "            \n",
    "    \n",
    "    def flow(self, X, y, batch_size=10000, feature_expender=None, \n",
    "             forecast_win=10,features_win=100):\n",
    "        ranges = np.arange(X.shape[0])\n",
    "        assert batch_size <= len(ranges)\n",
    "        while True:\n",
    "            np.random.shuffle(ranges)\n",
    "            for i in np.arange(0, len(ranges) - batch_size + 1, batch_size):\n",
    "                inds = ranges[i:i + batch_size]\n",
    "                x_batch, y_batch = X.iloc[inds], y[inds]\n",
    "                x_batch, y_batch = self.do_fucking_job(x_batch, y_batch,\n",
    "                                feature_expender, forecast_win, features_win)\n",
    "                yield (x_batch, y_batch)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.arange(9).reshape(3,3)\n",
    "b = np.arange(9).reshape(3,3)\n",
    "c = np.concatenate((a,b),axis=1)\n",
    "d = np.concatenate((a,b),axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[0, 1, 2, 0, 1, 2],\n",
       "        [3, 4, 5, 3, 4, 5],\n",
       "        [6, 7, 8, 6, 7, 8]]), array([[0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8],\n",
       "        [0, 1, 2],\n",
       "        [3, 4, 5],\n",
       "        [6, 7, 8]]))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c,d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    " df = pd.DataFrame({'B': [0, 1, 2, np.nan, 4]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     B\n",
       "0  0.0\n",
       "1  1.0\n",
       "2  2.0\n",
       "3  NaN\n",
       "4  4.0"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>B</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     B\n",
       "0  NaN\n",
       "1  0.0\n",
       "2  1.0\n",
       "3  2.0\n",
       "4  NaN"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shift(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
